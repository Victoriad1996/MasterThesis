{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f88e6118",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8e06681",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_convergence(list_losses, eps):\n",
    "    if len(list_losses)<3:\n",
    "        return False\n",
    "    else:\n",
    "        criterion = nn.MSELoss()\n",
    "        crit1 = criterion(torch.tensor(list_losses[-3]), torch.tensor(list_losses[-2]))\n",
    "        crit2 = criterion(torch.tensor(list_losses[-1]), torch.tensor(list_losses[-2]))\n",
    "        if crit1 + crit2 < eps:\n",
    "            return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e432e0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun(x):\n",
    "    x_bar = torch.mean(x)\n",
    "    N = x.shape[0]\n",
    "    one = torch.ones(N)\n",
    "    return torch.exp(x_bar + x_bar**3)*(one + 3*x**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc80181e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepDerSet(nn.Module):\n",
    "\n",
    "    def __init__(self, N):\n",
    "        super().__init__() # Runs initialisation of nn.Module\n",
    "        self.fc1 = nn.Linear(1, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 64)\n",
    "        self.fc4 = nn.Linear(64, 128)\n",
    "        self.fc5 = nn.Linear(128, 1024)\n",
    "        \n",
    "        self.psi1 = nn.Linear(N + 1024, 512)\n",
    "        self.psi2 = nn.Linear(512, 256)\n",
    "        self.psi3 = nn.Linear(256, N)\n",
    "        \n",
    "        self.N = N\n",
    "\n",
    "    def phi(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "        return x\n",
    "\n",
    "    def psi(self, x, y):\n",
    "        \n",
    "        z = torch.cat([x, y])\n",
    "        z = F.relu(self.psi1(z))\n",
    "        z = F.relu(self.psi2(z))\n",
    "        z = self.psi3(z)\n",
    "        return z\n",
    "        \n",
    "    def forward(self, x):\n",
    "        N = self.N\n",
    "        y = torch.zeros(N, 1024)\n",
    "        for i in range(N):\n",
    "            y[i] = self.phi(x[i].view(-1))\n",
    "        y = y.max(0).values\n",
    "        return self.psi(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b6a597d",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10\n",
    "n_data = 100\n",
    "x = torch.normal(torch.zeros(n_data, N), torch.ones(n_data, N)) \n",
    "synth = torch.zeros(n_data, N)\n",
    "for i in range(0,n_data):\n",
    "    f = fun(x[i, :])\n",
    "    synth[i,:] = fun(x[i, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6dd0c88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 10])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synth.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26f52602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS =  tensor(209.7650, grad_fn=<AddBackward0>)\n",
      "LOSS =  tensor(287.7296, grad_fn=<AddBackward0>)\n",
      "LOSS =  tensor(145.0028, grad_fn=<AddBackward0>)\n",
      "LOSS =  tensor(98.6237, grad_fn=<AddBackward0>)\n",
      "LOSS =  tensor(88.2992, grad_fn=<AddBackward0>)\n",
      "LOSS =  tensor(81.5720, grad_fn=<AddBackward0>)\n",
      "LOSS =  tensor(65.5426, grad_fn=<AddBackward0>)\n",
      "LOSS =  tensor(54.4400, grad_fn=<AddBackward0>)\n",
      "LOSS =  tensor(49.4401, grad_fn=<AddBackward0>)\n",
      "LOSS =  tensor(38.0237, grad_fn=<AddBackward0>)\n",
      "LOSS =  tensor(29.9978, grad_fn=<AddBackward0>)\n",
      "LOSS =  tensor(22.6054, grad_fn=<AddBackward0>)\n",
      "LOSS =  tensor(18.2709, grad_fn=<AddBackward0>)\n",
      "LOSS =  tensor(15.2249, grad_fn=<AddBackward0>)\n",
      "LOSS =  tensor(12.8097, grad_fn=<AddBackward0>)\n",
      "LOSS =  tensor(10.4496, grad_fn=<AddBackward0>)\n",
      "LOSS =  tensor(8.5627, grad_fn=<AddBackward0>)\n",
      "LOSS =  tensor(7.1972, grad_fn=<AddBackward0>)\n",
      "LOSS =  tensor(6.2132, grad_fn=<AddBackward0>)\n",
      "LOSS =  tensor(5.7475, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "batches = 10\n",
    "net = DeepDerSet(N).float()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.01) # Corresponds to evything that is adjustable\n",
    "criterion = nn.MSELoss()\n",
    "EPOCHS = 100\n",
    "outputs_epoch = []\n",
    "\n",
    "losses_epoch = []\n",
    "for epoch in range(EPOCHS):\n",
    "    loss_batch = []\n",
    "    for i in range(batches):\n",
    "        net.zero_grad()\n",
    "        k = int(n_data /batches)\n",
    "        dataX = x[i:i+k,:]\n",
    "        dataY = synth[i:i+k,:]\n",
    "        tot_loss = 0\n",
    "        net.zero_grad()\n",
    "        for j , (X, Y) in enumerate(zip(dataX, dataY)):\n",
    "            output = net(X)\n",
    "            loss = criterion(output, Y)\n",
    "            tot_loss += loss\n",
    "            loss_batch.append(loss)\n",
    "        tot_loss.backward() # Backpropagate the loss\n",
    "        optimizer.step() # Adjusts the steps\n",
    "    losses_epoch.append(loss_batch)\n",
    "    print('LOSS = ', tot_loss)\n",
    "    if test_convergence(losses_epoch, 0.1):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50453779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(losses_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f04f8622",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c35b05fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'DeepDerSet')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.close()\n",
    "for i, tot_losses in enumerate(losses_epoch[4:]):\n",
    "    if i%k == 0:\n",
    "        plt.plot(tot_losses, label=str(i+4))\n",
    "plt.legend()\n",
    "plt.title(\"DeepDerSet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e06c56e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0580, 2.0044, 4.6719, 3.1931, 2.8831, 6.4153, 1.0592, 2.9822, 5.4159,\n",
       "        3.1815], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e6db1329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.3056],\n",
       "         [ 0.7570],\n",
       "         [ 0.9986],\n",
       "         [ 0.7285],\n",
       "         [-0.7082],\n",
       "         [ 0.9352],\n",
       "         [-0.9268],\n",
       "         [-0.2776],\n",
       "         [ 0.7805],\n",
       "         [ 0.7518],\n",
       "         [ 0.9174],\n",
       "         [ 0.3512],\n",
       "         [-0.1418],\n",
       "         [ 0.5707],\n",
       "         [-0.6647],\n",
       "         [-0.6440],\n",
       "         [-0.9561],\n",
       "         [-0.0090],\n",
       "         [-0.0794],\n",
       "         [ 0.5561],\n",
       "         [ 0.8119],\n",
       "         [ 0.7834],\n",
       "         [ 0.3158],\n",
       "         [-0.3996],\n",
       "         [ 0.9475],\n",
       "         [-0.3849],\n",
       "         [-0.4243],\n",
       "         [-0.3241],\n",
       "         [ 0.1463],\n",
       "         [-0.8588],\n",
       "         [-0.9332],\n",
       "         [-0.2000],\n",
       "         [ 0.1989],\n",
       "         [-0.8560],\n",
       "         [-0.3007],\n",
       "         [-0.7218],\n",
       "         [-0.4654],\n",
       "         [ 0.3900],\n",
       "         [-0.0189],\n",
       "         [-0.1893],\n",
       "         [-0.1125],\n",
       "         [ 0.8380],\n",
       "         [ 0.1887],\n",
       "         [-0.3842],\n",
       "         [-0.2653],\n",
       "         [-0.5734],\n",
       "         [ 0.5967],\n",
       "         [-0.3252],\n",
       "         [ 0.8905],\n",
       "         [-0.2820],\n",
       "         [ 0.8554],\n",
       "         [-0.8724],\n",
       "         [-0.8012],\n",
       "         [ 0.4306],\n",
       "         [ 0.6392],\n",
       "         [-0.8788],\n",
       "         [-0.2423],\n",
       "         [ 0.4686],\n",
       "         [-0.1080],\n",
       "         [ 0.8544],\n",
       "         [-0.1748],\n",
       "         [-0.1978],\n",
       "         [ 0.4557],\n",
       "         [ 0.9153]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.8419, -0.2163, -0.4287,  0.8248, -0.3139,  0.6300, -0.4868, -0.5946,\n",
       "         -0.1051, -0.4192,  0.6147, -0.5141,  0.4023,  0.0716, -0.5277, -0.3930,\n",
       "         -0.2906, -0.5751,  0.5490,  0.5039,  0.0036,  0.4830, -0.9919, -0.4644,\n",
       "         -0.3742,  0.9265,  0.0578, -0.4719, -0.4719,  0.0038, -0.3900,  0.8450,\n",
       "          0.5875, -0.9062, -1.0000, -0.8752,  0.1791, -0.3968, -0.4718, -0.8220,\n",
       "          0.7591,  0.8450, -0.4687, -0.1566, -0.7372,  0.7582, -0.3736, -0.7194,\n",
       "         -0.5565, -0.6461, -0.2194, -1.0237,  0.6343,  0.1921,  0.3462, -0.6282,\n",
       "          0.4791,  0.4199,  0.7320,  0.8233,  0.9225,  0.4420, -0.0471, -0.7035],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.0953,  0.0275, -0.1501,  ..., -0.0506, -0.1342, -0.1525],\n",
       "         [-0.0196, -0.0693, -0.0097,  ...,  0.0159, -0.0225,  0.0616],\n",
       "         [ 0.0679, -0.0062, -0.1748,  ..., -0.0944,  0.0728, -0.0387],\n",
       "         ...,\n",
       "         [-0.0284, -0.0241,  0.0416,  ..., -0.1104, -0.0243,  0.0868],\n",
       "         [-0.0716, -0.1474, -0.1037,  ...,  0.0329, -0.1512, -0.0849],\n",
       "         [ 0.0198,  0.0361, -0.0376,  ..., -0.1094,  0.0331,  0.0369]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0229,  0.0287, -0.1682,  0.0439, -0.1271, -0.0708, -0.0637,  0.0321,\n",
       "          0.0227, -0.0606, -0.1376, -0.1192, -0.1687, -0.0792, -0.1648, -0.1297,\n",
       "          0.0726, -0.0388,  0.0589, -0.1472, -0.0938,  0.0078,  0.0652,  0.0355,\n",
       "         -0.0255, -0.0910, -0.1039, -0.0615, -0.1479,  0.0108,  0.0436, -0.1459,\n",
       "         -0.1389,  0.0050,  0.0151,  0.0444, -0.0843, -0.0224,  0.0449, -0.1046,\n",
       "          0.0657, -0.0048, -0.0489,  0.0125, -0.1584, -0.0715,  0.0710, -0.1481,\n",
       "         -0.0042, -0.0126, -0.0995,  0.0498, -0.0470,  0.0240, -0.0560, -0.0808,\n",
       "         -0.0063, -0.0893, -0.0470, -0.0752,  0.0208,  0.0622, -0.0121,  0.0262],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.0559, -0.0651,  0.0164,  ...,  0.0187,  0.0204, -0.1602],\n",
       "         [-0.0631, -0.0223, -0.0585,  ..., -0.0461,  0.0368, -0.0406],\n",
       "         [ 0.0655, -0.0769, -0.0636,  ...,  0.0350, -0.1303, -0.1644],\n",
       "         ...,\n",
       "         [ 0.0161, -0.0208,  0.0129,  ..., -0.0454,  0.0345, -0.0600],\n",
       "         [ 0.0498, -0.0465, -0.0320,  ...,  0.0817,  0.0985,  0.0393],\n",
       "         [-0.0556, -0.0513,  0.0242,  ...,  0.1168,  0.0677, -0.1172]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0394, -0.0143, -0.0896, -0.1421,  0.0562, -0.0649, -0.0710,  0.0095,\n",
       "         -0.1384, -0.0353, -0.1339, -0.0842,  0.0591,  0.1698, -0.0344,  0.0083,\n",
       "         -0.0060, -0.0427,  0.0701, -0.1813,  0.0246, -0.1257,  0.0647, -0.0046,\n",
       "         -0.1565, -0.1134, -0.0524, -0.0126, -0.0647, -0.0718,  0.0485, -0.0551,\n",
       "          0.0379, -0.1553,  0.0973, -0.0853,  0.0696, -0.1547, -0.0901, -0.0610,\n",
       "          0.0217, -0.0373, -0.1014, -0.0729, -0.0287,  0.0803, -0.0293, -0.1376,\n",
       "          0.0291, -0.0789,  0.0240, -0.1515, -0.1342,  0.0539, -0.0937, -0.0780,\n",
       "         -0.1451, -0.0194, -0.1137, -0.1348,  0.0205,  0.0103, -0.1035, -0.0050],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.0127, -0.1028,  0.1079,  ..., -0.0842, -0.0078, -0.0697],\n",
       "         [ 0.0233,  0.0049,  0.0088,  ...,  0.0152, -0.1172, -0.1387],\n",
       "         [-0.1554, -0.0628,  0.0539,  ...,  0.0583, -0.1508, -0.1449],\n",
       "         ...,\n",
       "         [-0.1245,  0.0335,  0.0771,  ...,  0.0585, -0.1477, -0.0714],\n",
       "         [-0.1148,  0.1024, -0.1276,  ..., -0.0075, -0.0289, -0.0118],\n",
       "         [-0.0700, -0.0114, -0.0795,  ...,  0.0327, -0.1290,  0.0900]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.1092,  0.0295, -0.1189, -0.1051, -0.1048, -0.0907, -0.1401, -0.0371,\n",
       "         -0.0716, -0.0375,  0.0915, -0.1239,  0.0069, -0.0648, -0.1188, -0.0620,\n",
       "         -0.1668, -0.1414, -0.0868, -0.0120, -0.0703,  0.0543, -0.0099, -0.0303,\n",
       "         -0.0721, -0.0866, -0.1205, -0.0903, -0.1647, -0.0140, -0.0829, -0.0039,\n",
       "         -0.0512, -0.0934,  0.0371, -0.0030, -0.1102, -0.0925,  0.0504,  0.0468,\n",
       "         -0.0249, -0.0757, -0.0756,  0.0118,  0.0794, -0.1215, -0.0629,  0.0084,\n",
       "         -0.0522, -0.1051, -0.1312, -0.0695,  0.0950, -0.1393, -0.0813, -0.0066,\n",
       "         -0.1076, -0.0934,  0.0200,  0.0137, -0.2081, -0.0506,  0.0524,  0.0297,\n",
       "          0.0353, -0.1315,  0.0770, -0.1146, -0.0177, -0.1561,  0.0028, -0.0508,\n",
       "         -0.0839,  0.0580, -0.0080, -0.1198,  0.0325,  0.0576, -0.1035, -0.1215,\n",
       "         -0.0020,  0.0097, -0.0837, -0.0216, -0.1063,  0.0311, -0.1530,  0.0230,\n",
       "         -0.0712, -0.0476, -0.0638,  0.0121, -0.1458,  0.0481, -0.0501,  0.0328,\n",
       "         -0.0525, -0.0786, -0.0124, -0.1447, -0.0543, -0.0017,  0.0299, -0.0191,\n",
       "          0.0763, -0.1631, -0.0716, -0.1348, -0.1440, -0.0419, -0.0842,  0.0545,\n",
       "         -0.0552,  0.0155,  0.0592,  0.0048, -0.0671, -0.0299, -0.0493,  0.0116,\n",
       "          0.0135, -0.0264, -0.0378,  0.0213,  0.0167, -0.1530, -0.0691, -0.0152],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.0813,  0.0448, -0.0779,  ..., -0.0018,  0.0869, -0.0285],\n",
       "         [-0.0088, -0.0105, -0.1284,  ..., -0.0195,  0.0465,  0.0775],\n",
       "         [-0.0623, -0.0511,  0.0348,  ..., -0.0030, -0.0150,  0.0160],\n",
       "         ...,\n",
       "         [-0.0573,  0.0500, -0.0761,  ...,  0.0740,  0.0718, -0.0066],\n",
       "         [ 0.0511, -0.0295, -0.0010,  ..., -0.0161, -0.0130, -0.0010],\n",
       "         [ 0.0589,  0.0770, -0.0070,  ...,  0.0520, -0.0907, -0.0166]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0008,  0.0562,  0.0643,  ...,  0.0388, -0.0883, -0.0864],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.0367, -0.0234,  0.0382,  ..., -0.0517, -0.0211,  0.0061],\n",
       "         [-0.0937,  0.1214,  0.1022,  ..., -0.0279, -0.0659, -0.0640],\n",
       "         [-0.1065,  0.0199, -0.0136,  ..., -0.0514, -0.0223, -0.0303],\n",
       "         ...,\n",
       "         [-0.0858,  0.1060,  0.1109,  ..., -0.0474, -0.0973, -0.0810],\n",
       "         [-0.0594,  0.0543,  0.0498,  ..., -0.0603, -0.0426, -0.0105],\n",
       "         [-0.0039,  0.0433, -0.0014,  ..., -0.0250, -0.0504,  0.0092]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0546, -0.0339, -0.0789, -0.0560, -0.0623, -0.0338, -0.0019, -0.0493,\n",
       "         -0.0928, -0.0450, -0.0797, -0.0762, -0.0417, -0.0580, -0.0565, -0.0641,\n",
       "         -0.0336, -0.0643, -0.0444, -0.0460, -0.0502, -0.0321, -0.0874, -0.0968,\n",
       "         -0.0403, -0.0291, -0.0513, -0.0359, -0.0276, -0.0533, -0.0730, -0.0072,\n",
       "         -0.0988, -0.0084, -0.0445, -0.0294, -0.0108, -0.0216, -0.0018, -0.0208,\n",
       "         -0.0309, -0.0367, -0.0757, -0.0539, -0.0658, -0.0401, -0.0042, -0.0564,\n",
       "         -0.0880, -0.0562, -0.0919, -0.0171, -0.0228, -0.0022,  0.0308, -0.0827,\n",
       "         -0.0347, -0.0106, -0.0314, -0.0505, -0.0067, -0.0827, -0.0491, -0.0628,\n",
       "         -0.0238, -0.0429, -0.0619, -0.0566, -0.0444, -0.1026, -0.0968, -0.0692,\n",
       "         -0.0865, -0.0931, -0.0520, -0.0356, -0.0130, -0.0874, -0.0510, -0.0407,\n",
       "         -0.0454, -0.0559, -0.0325, -0.0319, -0.0408, -0.0180, -0.0224, -0.0234,\n",
       "         -0.0599, -0.0560, -0.0741, -0.0555, -0.0790, -0.0352, -0.0061, -0.0864,\n",
       "         -0.0235, -0.0561, -0.0224, -0.0091, -0.0716, -0.0843, -0.1071, -0.0334,\n",
       "         -0.0498, -0.0591, -0.0740, -0.1043, -0.0075, -0.0804, -0.0351, -0.0862,\n",
       "         -0.0077, -0.0240,  0.0058, -0.0587, -0.0396, -0.0266, -0.0733, -0.0373,\n",
       "         -0.0263, -0.0602, -0.0568, -0.0829, -0.0457, -0.0499, -0.0675, -0.0143,\n",
       "         -0.0976, -0.0424, -0.0947, -0.0287, -0.0147, -0.0354, -0.0864, -0.0433,\n",
       "         -0.0699, -0.0225, -0.0231, -0.0487, -0.0392, -0.0284, -0.0211, -0.0551,\n",
       "         -0.0506, -0.0645, -0.0529, -0.0144, -0.0593, -0.0633, -0.0359, -0.0717,\n",
       "         -0.0713, -0.0117, -0.0759, -0.0964, -0.0490, -0.0226, -0.0213, -0.0738,\n",
       "         -0.0348, -0.0631, -0.0581, -0.0494, -0.0621, -0.0658,  0.0080, -0.0292,\n",
       "         -0.0583, -0.0894, -0.0229, -0.0954, -0.0114, -0.0955, -0.0590, -0.0341,\n",
       "         -0.0579, -0.0250, -0.0841, -0.0261, -0.0726, -0.0751, -0.0485, -0.0701,\n",
       "         -0.0429, -0.0331, -0.0101, -0.0285, -0.0468, -0.0236, -0.0646, -0.0512,\n",
       "         -0.0543, -0.0133, -0.0832, -0.0517, -0.0156, -0.0723, -0.1634, -0.0916,\n",
       "         -0.0395, -0.0209, -0.0591, -0.0724, -0.0930, -0.0984, -0.0623, -0.0235,\n",
       "         -0.0492, -0.0486, -0.0641, -0.0546, -0.0692, -0.1023, -0.0625, -0.0904,\n",
       "         -0.0694, -0.0312, -0.0355, -0.0499, -0.0908, -0.0879, -0.0829, -0.0603,\n",
       "         -0.0360, -0.0390, -0.0862, -0.0645, -0.0781, -0.0547, -0.0452, -0.0593,\n",
       "         -0.0338, -0.0421, -0.0348, -0.0495, -0.0668, -0.0415, -0.0472, -0.0694,\n",
       "         -0.0241, -0.0587, -0.0177, -0.0520, -0.0659, -0.0683, -0.0700, -0.0354,\n",
       "         -0.0483, -0.0254, -0.0789, -0.0406, -0.0635, -0.0373, -0.0512, -0.0487,\n",
       "         -0.0956, -0.0481, -0.0365, -0.0507, -0.0806, -0.0379, -0.0592, -0.0490,\n",
       "         -0.0515, -0.0326, -0.0824, -0.0795, -0.0435, -0.0740, -0.0063, -0.0207,\n",
       "         -0.0593, -0.0164, -0.0851, -0.0507, -0.0391, -0.0215, -0.0635, -0.0308,\n",
       "         -0.0305, -0.0450, -0.0583, -0.0800, -0.0541, -0.0112, -0.0611, -0.0293,\n",
       "         -0.0183,  0.0144, -0.0388, -0.0610, -0.0710, -0.0845, -0.0228, -0.0805,\n",
       "         -0.0602, -0.0381, -0.0383, -0.1617, -0.0421, -0.0519, -0.0767, -0.0690,\n",
       "         -0.0382, -0.0589, -0.0591, -0.0619, -0.0499, -0.0823, -0.0168, -0.0146,\n",
       "         -0.0678, -0.0402, -0.0704, -0.0488, -0.0456, -0.0121, -0.0214, -0.0375,\n",
       "         -0.0147, -0.0871, -0.0361, -0.0760, -0.0264, -0.0874, -0.0273, -0.0320,\n",
       "         -0.0423, -0.0736, -0.0660, -0.0799, -0.0668, -0.0335, -0.0504, -0.0534,\n",
       "         -0.0480, -0.0205, -0.0747,  0.1196, -0.1069, -0.0384, -0.0577, -0.0411,\n",
       "         -0.0522, -0.0342, -0.0541, -0.1014, -0.0322, -0.0505, -0.0621, -0.0192,\n",
       "         -0.0367, -0.0217, -0.0394, -0.0938, -0.0058, -0.0445, -0.0638, -0.0093,\n",
       "         -0.0791, -0.0641, -0.0443, -0.0266, -0.0344, -0.0528, -0.0866, -0.0555,\n",
       "         -0.0879, -0.0433, -0.0361, -0.0294, -0.0567, -0.0638, -0.0516, -0.0497,\n",
       "         -0.0614, -0.0604, -0.0435, -0.0682, -0.0380, -0.0490, -0.0311, -0.0533,\n",
       "         -0.0940, -0.0576, -0.0884, -0.0783, -0.0609, -0.0608, -0.0187, -0.0313,\n",
       "         -0.0901, -0.0647, -0.0105, -0.0837, -0.0518, -0.0921, -0.0060, -0.0683,\n",
       "         -0.0775, -0.0345, -0.0585, -0.0525, -0.0410, -0.0646, -0.0357, -0.0812,\n",
       "         -0.0680, -0.0583, -0.0746, -0.0610, -0.0402, -0.0833, -0.0113, -0.0439,\n",
       "         -0.0661, -0.0418, -0.0876, -0.0208, -0.0397, -0.0462, -0.0207, -0.0200,\n",
       "         -0.0323, -0.0451, -0.0537, -0.0447, -0.0669, -0.0655, -0.0814, -0.0114,\n",
       "         -0.0389, -0.0454, -0.0519, -0.0265, -0.0459, -0.0572, -0.0474, -0.0898,\n",
       "         -0.0608, -0.0873, -0.0314, -0.0373, -0.1101, -0.0810, -0.0070, -0.0257,\n",
       "         -0.0458, -0.0696, -0.0469, -0.0271, -0.0536, -0.0806, -0.0625, -0.0294,\n",
       "         -0.0343, -0.0832, -0.0401, -0.0266, -0.0215, -0.0667, -0.0467, -0.0437,\n",
       "         -0.0433, -0.0422, -0.1654, -0.0543, -0.0576, -0.0309, -0.0280, -0.0588,\n",
       "         -0.0733, -0.1237, -0.0607, -0.0665, -0.0953, -0.0428, -0.0885, -0.0420,\n",
       "         -0.0496, -0.0279, -0.0359, -0.0386, -0.0777, -0.0659, -0.0745, -0.0466,\n",
       "         -0.0683, -0.0715, -0.0616, -0.0055, -0.0466, -0.0353, -0.0389, -0.0540,\n",
       "         -0.0412, -0.0652,  0.0869, -0.0369, -0.0301, -0.0134, -0.0152, -0.0159,\n",
       "         -0.0439, -0.0445, -0.0407, -0.0541, -0.0352, -0.0616, -0.0882, -0.0767],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.0161, -0.0494, -0.0646,  ..., -0.0416,  0.0035,  0.0039],\n",
       "         [ 0.0428, -0.0092, -0.0157,  ...,  0.0102, -0.0434, -0.0026],\n",
       "         [-0.0115,  0.0051, -0.0013,  ...,  0.0143, -0.0915, -0.0577],\n",
       "         ...,\n",
       "         [-0.0096, -0.0359, -0.0245,  ..., -0.0318, -0.0345, -0.0834],\n",
       "         [-0.0310, -0.0796, -0.0335,  ..., -0.0380, -0.0239, -0.0745],\n",
       "         [ 0.0151, -0.0689, -0.0574,  ..., -0.0465, -0.0528,  0.0070]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-6.0825e-03,  2.9327e-02, -9.5434e-02, -5.1512e-02, -8.1280e-02,\n",
       "         -6.4023e-02, -1.0219e-01,  7.9110e-02, -5.2008e-02, -4.0032e-03,\n",
       "         -1.1990e-02, -8.4170e-02, -1.4500e-04, -3.7062e-02, -9.6829e-02,\n",
       "         -2.4070e-01, -4.8750e-02, -1.3109e-01, -1.2706e-02,  1.0195e-01,\n",
       "         -2.9581e-02, -1.9546e-01, -2.3238e-03,  3.1718e-01, -4.7194e-02,\n",
       "         -8.2514e-02, -4.6019e-02, -4.2371e-02,  2.3436e-01,  2.9518e-01,\n",
       "          2.1598e-01, -3.9258e-02, -6.8220e-02, -9.8006e-02, -4.1834e-02,\n",
       "          8.5784e-02, -5.2567e-02, -3.6059e-03, -6.0494e-02, -3.1061e-02,\n",
       "         -1.8070e-02,  1.1511e-01,  4.7257e-01,  3.3230e-01, -6.0494e-02,\n",
       "          2.4449e-01, -1.4172e-01, -4.3138e-02, -9.3417e-02, -2.7565e-02,\n",
       "         -6.3006e-02,  1.9385e-01, -9.9581e-02, -5.5248e-02, -1.3364e-01,\n",
       "         -2.4925e-02, -1.0992e-01, -5.7729e-02,  3.2864e-01, -8.3140e-03,\n",
       "          1.4379e-02, -7.9641e-02, -3.8725e-02,  3.4584e-02, -5.6711e-02,\n",
       "          4.0317e-03, -7.0276e-02, -1.0244e-02, -1.5841e-01, -4.2138e-02,\n",
       "         -4.4513e-02, -7.1681e-02,  1.7572e-01,  3.7718e-01, -1.0539e-01,\n",
       "          1.9441e-03, -3.4036e-02,  2.9184e-01,  1.7574e-01, -1.3246e-01,\n",
       "         -2.9366e-01,  4.3442e-01,  3.0344e-01, -2.8078e-02,  2.6264e-01,\n",
       "         -3.9278e-02, -6.7943e-02,  2.1439e-01, -2.1813e-02, -1.1338e-01,\n",
       "         -8.0188e-02, -3.9933e-03, -9.1059e-02, -5.5420e-02, -5.9236e-03,\n",
       "         -5.9707e-02,  1.0906e-01, -1.6228e-01, -3.0352e-02, -3.0257e-02,\n",
       "          3.4976e-01,  3.1258e-01, -3.4424e-02, -3.9427e-01,  3.1607e-01,\n",
       "         -4.6937e-02, -2.6595e-02,  3.7943e-02, -7.8480e-02,  3.1226e-01,\n",
       "          3.1839e-01, -9.6656e-02, -9.5621e-02, -8.6237e-02, -5.5014e-02,\n",
       "          2.2575e-01, -8.0735e-03, -7.0298e-02, -3.1012e-02, -3.0898e-02,\n",
       "         -4.5853e-02, -1.1024e-01, -6.2363e-02, -1.9984e-01, -1.3338e-01,\n",
       "         -3.0940e-02,  9.4751e-02,  3.0563e-01, -9.0830e-02, -1.7140e-01,\n",
       "         -6.0479e-02, -2.1244e-02, -8.1145e-02, -5.7482e-02, -7.0690e-02,\n",
       "         -1.9755e-01, -5.9928e-02, -1.9336e-02, -4.2263e-03, -6.3790e-02,\n",
       "         -3.3073e-02, -1.5552e-01, -6.3011e-02,  3.6383e-01, -3.6065e-02,\n",
       "         -1.0849e-01,  2.5474e-03,  2.1263e-01, -3.6271e-02, -3.0400e-02,\n",
       "          3.2573e-01, -1.0711e-02, -7.5849e-02, -5.6179e-02, -6.0919e-01,\n",
       "          2.5856e-01, -6.5062e-02, -1.6819e-01,  1.5106e-02, -1.3432e-01,\n",
       "         -2.5574e-01, -3.8854e-02,  1.0291e-01, -5.1012e-02, -5.1787e-02,\n",
       "          2.9623e-02, -5.2701e-02, -1.7062e-02, -8.2387e-02,  1.2458e-01,\n",
       "         -9.6992e-02, -2.3009e-03,  4.6437e-01,  3.9792e-01,  2.8752e-01,\n",
       "          3.1469e-01, -9.6509e-02, -6.5927e-02,  4.4050e-01, -2.5749e-02,\n",
       "         -5.2606e-02, -1.1974e-01, -7.8571e-02, -6.5706e-02,  2.0911e-01,\n",
       "         -5.4214e-02, -3.1279e-02, -5.6852e-02, -4.8163e-02, -1.2225e-03,\n",
       "         -2.1031e-02, -5.1192e-02, -7.5084e-02, -5.8289e-02, -5.7197e-02,\n",
       "          2.6867e-01, -1.9133e-02, -3.7617e-02, -5.4717e-02,  6.6863e-02,\n",
       "         -2.3652e-02, -5.2005e-01, -9.9523e-02,  2.5124e-01, -6.3917e-02,\n",
       "         -8.3877e-02, -3.7932e-01, -6.5091e-02,  2.5964e-01, -2.6030e-02,\n",
       "         -6.0999e-02, -6.4667e-02, -9.8969e-02,  3.3031e-01, -1.8856e-02,\n",
       "         -2.1962e-01, -5.2723e-02, -5.2625e-02, -9.6247e-02, -6.0994e-02,\n",
       "         -4.7243e-02, -5.8072e-02, -5.7694e-02,  2.1612e-01,  3.5660e-01,\n",
       "         -3.1131e-02,  1.7988e-01, -7.1624e-02, -3.5641e-02,  3.3713e-03,\n",
       "          3.9762e-01, -2.8078e-02,  2.0793e-01, -2.3130e-02, -1.1084e-01,\n",
       "         -5.8908e-02,  3.0648e-01, -8.8349e-02,  3.6676e-02, -1.2689e-02,\n",
       "         -2.7688e-02, -3.9648e-03,  2.3696e-01, -2.6363e-02, -2.4726e-02,\n",
       "         -5.6568e-02,  1.2535e-02, -1.8361e-02, -6.9797e-02, -6.3215e-02,\n",
       "         -2.7701e-02, -3.1298e-02,  1.4193e-01,  6.4844e-01,  2.2027e-01,\n",
       "         -8.5868e-02], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.0350, -0.0120, -0.0040,  ...,  0.1902,  0.0321, -0.0283],\n",
       "         [ 0.0092,  0.0958, -0.0846,  ..., -0.2756,  0.1823, -0.0797],\n",
       "         [ 0.0022,  0.0203,  0.0187,  ..., -0.0178,  0.0295, -0.0448],\n",
       "         ...,\n",
       "         [-0.0786, -0.0049, -0.0746,  ...,  0.4985,  0.0723, -0.0721],\n",
       "         [ 0.0058,  0.2195, -0.0938,  ...,  0.0569, -0.0052, -0.0215],\n",
       "         [-0.0595,  0.2281,  0.0129,  ..., -0.1809,  0.1894, -0.0231]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0320,  0.0452,  0.0855,  0.0396,  0.2073,  0.1130,  0.2609,  0.3177,\n",
       "          0.2418,  0.0744], requires_grad=True)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cd3f58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
